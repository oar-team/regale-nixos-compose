---
title: "bebida-optimization-result-analysis"
author: "Michael Mercier"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Motivations

We want to evaluate heuristics that we have implemented to improve the quality of service for the application that are running with Bebida (called Bebida applications). Indeed, these applications are running using Idle HPC resources but be preempted at any time by a starting HPC job, which implies an undefined execution time if the HPC cluster is loaded.

To cope with this issue, we developed some mechanism that allows to provided dedicated resources to the Bebida application and thus improve their quality of service.
The first mechanism called *Punch* is to watch the Kubernetes queue to detect pending application. When detected, a job is created in the HPC queue with a special attribute that tells the HPC prologue to leave the Kubernetes daemon running, thus, during this HPC job the resources are dedicated to the Bebida applications.
To determine the size of the Punch job in number of resources and time, the Bebida applications are annotated with resource requirements. Another requirement is the optional deadline that a user can provide.
In this case, the Punch job is delayed to finish just before the deadline in order to avoid unnecessary disruption of the HPC workload.

The second mechanism is called *Refill*. It creates a fluid dynamic partitioning of the resource using resource quota. The HPC scheduler is configured to always keep a defined amount of resources free of job, which make them available for the Bebida applications. These resources are considered fluid because this is not a static partition od the cluster that is reserved but an amount of resource which is not pinned to a particular set of resource. This is a dynamic partition because the amount of reserved resources can change over time. For now, we use annotations on Bebida application to trigger the increase of reserved resources and decrease it when the application ends. A more interesting policy would be to use historical data to increase the response time with prescriptive decisions instead of reactive ones, but this is out of the scope of this experiment.

## Experiment Design

### Heuristics

This experiment is design to evaluate the impact of different variants of the aforementioned mechanism. We defined the following heuristics:

* NoHPC: In order to have a control experiment, run the Bebida app without HPC workload
* None: Raw Bebida implementation without optimization
* Punch: Create jobs at submission time with arbitrary resource requests
* Refill: Use resource quota to dedicate a dynamic set of resources to time critical Bebida applications

The Deadline goal is to run before a given deadline. Because it does not follow the same objective it is not to be compared to the others.

### Workloads

For this experiment, we run a Spark example application (SparkPi) 4 time in a row using the same heuristic, with 5 sec between each run.
Meanwhile, we emulate an HPC workload generated by LightESP. It starts 10sec before the first Spark application, so the cluster is already loaded with HPC job when the first application starts, and still submits jobs until the end of the last run.

### Platform

The platform used for this experiment is Grid5000. We use the 16 nodes on the Gros cluster in the Nancy site. Details of the cluster are available here: https://www.grid5000.fr/w/Nancy:Hardware#gros

The deployment of the system is done in a reproducible manner using [NixOS-Compose](https://github.com/oar-team/nixos-compose). It allows use to easily deploy a reproducible software environment defined in a declarative way called a composition. The composition used for this experiment is available [here](https://github.com/oar-team/regale-nixos-compose/tree/main/bebida). The environement created contains includes an HPC scheduler ([OAR](https://oar-3.readthedocs.io) is used for this experiment but [Slurm](https://slurm.schedmd.com/) is also available), a lightweight Kubernetes called [k3s](https://k3s.io/), and the [Bebida optimization service](https://github.com/RyaxTech/bebida-optimization-service) that implement the heuristics.


## Bebida Applications Execution time Analysis

Initialize Libraries
```{r}
library(tidyverse)
library(viridisLite)
library(rjson)
```

Get data from the experiment result directory:
```{r expeDirs}
resultDir = "/home/mmercier/Projects/bebida-optimization-service/result-all-4/"

expeDirs = Sys.glob(sprintf("%s/*", resultDir))
expeDirs
```

Extract BDA applications metrics:
```{r bdaDf}

bdaDf <- data.frame(heuristic = character(), execution_time = integer())

for (expeDir in expeDirs) {
  execTime = array()
  metadata <- fromJSON(file=sprintf("%s/metadata.json", expeDir))
  
  for (iteration in 1:metadata$nb_app_run) {
    possibleError <- tryCatch({
      podState <- fromJSON(file=sprintf("%s/spark-app-pi-%d-pod.json", expeDir, iteration))
  
    startTime = parse_datetime(podState$status$containerStatuses[[1]]$state$terminated$startedAt)
    endTime = parse_datetime(podState$status$containerStatuses[[1]]$state$terminated$finishedAt)

    bdaDf <- bdaDf %>% add_row(heuristic = metadata$heuristic, execution_time = as.numeric(difftime(endTime,startTime),units="secs"))
    }, error=function(e) e)
    if(inherits(possibleError, "error")) next
  }
}
bdaDf
```
Number of runs per Heuristics are:
```{r}
bdaDf %>% count(heuristic)
```
Extract HPC Jobs metrics.

WARNING: Some job give a submission time after the starting time. which gives a negative waiting time. These jobs are excluded.
```{r}

hpcDf <- data.frame(heuristic = character(), job_id = character(), job_name = character(), waiting_time = integer())

for (expeDir in expeDirs) {

  hpcJobs <- fromJSON(file=sprintf("%s/oar-jobs.json", expeDir))
  metadata <- fromJSON(file=sprintf("%s/metadata.json", expeDir))
  
  for (job in hpcJobs) {
    submitTime = as.POSIXct(job$submission_time, origin="1970-01-01")
    startTime = as.POSIXct(job$start_time, origin="1970-01-01")
    job_id = as.character(job$id)
    waiting_time = as.numeric(difftime(startTime,submitTime),units="secs")

    if (waiting_time > 0 && ! grepl("BEBIDA_NOOP", job$name, fixed = TRUE)) {
      hpcDf <- hpcDf %>% add_row(
        heuristic=metadata$heuristic, job_id=job_id, job_name=job$name, waiting_time=waiting_time) 
    }
  }
}
hpcDf
```

## Bebida application execution time

```{r}
bdaDf %>%
  ggplot() +
  geom_boxplot(aes(x=heuristic, y=execution_time, fill=heuristic, group=heuristic, ymin=0))
```

Transform raw data to stats
```{r}
bdaDfStats <- bdaDf %>%
  group_by(heuristic) %>%
  summarise( 
    n=n(),
    mean=mean(execution_time),
    sd=sd(execution_time)
  ) %>%
  mutate( se=sd/sqrt(n))  %>%
  mutate( ic=se * qt((1-0.05)/2 + .5, n-1))
bdaDfStats
```
```{r}
mean_none = (bdaDfStats[bdaDfStats$heuristic == "none",]$mean)
sd_none = (bdaDfStats[bdaDfStats$heuristic == "none",]$sd)

bdaDfStats %>%
  mutate(mean_diff_percent= (mean - mean_none) * 100 / mean_none) %>%
  mutate(sd_diff_perdent= (sd - sd_none) * 100 / sd_none)

# Only keep what's needed
bdaDfStats <- bdaDfStats %>%
  filter(heuristic != "annotated") %>%
  filter(heuristic != "deadline")
bdaDfStats
```

```{r}
bdaDfStats %>%
  ggplot() +
  geom_bar( aes(x=heuristic, y=mean, fill=heuristic), stat="identity", alpha=0.5) +
  geom_errorbar(aes(x=heuristic, ymin=mean-sd, ymax=mean+sd), width=0.4, colour="orange", alpha=0.9, size=1.3) +
  ggtitle("Mean execution time in seconds (with standard deviation)")

```

The first figure shows that the application running alone (nohpc) has a stable the execution time. Using Bebida without optimization (none) the Bebida applications runs longer with large uncertainty on the execution time which is expected because it depends on small time frames that sometimes match task execution and sometimes dont.

Regarding the heuristics proposed in this work, we can see that for the Punch method reduce the mean execution time by 4,4% when compared to the None heuristic but also decrease significantly the variability (-18%). The Refill method improve the mean execution by 11,5% and the decrease the variability by 32%.


## Impact on HPC work

```{r}
hpcDf  %>%
  filter(heuristic != "annotated") %>%
  filter(heuristic != "deadline") %>%
  ggplot() +
  geom_boxplot(aes(x=heuristic, y=waiting_time, fill=heuristic, group=heuristic, ymin=0))
```


In this box plot we see that the heuristics also have impact on the HPC jobs' waiting time because, for *Punch* it insect jobs in the workload and for *Refill* it reduce the amount of resources available.
